{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01fb543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# allow importing local modules (preprocess)\n",
    "        # allow importing local modules (preprocess)\n",
    "        # __file__ is not available in notebooks — locate repo root by searching upward for src/models/preprocess.py\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "repo_root = pathlib.Path().cwd()\n",
    "found = False\n",
    "p = repo_root\n",
    "\n",
    "for _ in range(10):\n",
    "    candidate = p / 'src' / 'models' / 'preprocess.py'\n",
    "    \n",
    "    if candidate.exists():\n",
    "        repo_root = p\n",
    "        found = True\n",
    "        break\n",
    "    \n",
    "    if p.parent == p:  # chegou na raiz do SO\n",
    "        break\n",
    "    \n",
    "    p = p.parent\n",
    "\n",
    "if not found:\n",
    "    # fallback to cwd\n",
    "    repo_root = pathlib.Path().cwd()\n",
    "\n",
    "# add local models folder to sys.path\n",
    "sys.path.append(str(repo_root / 'src' / 'models'))\n",
    "\n",
    "from preprocess import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc73365",
   "metadata": {},
   "outputs": [],
   "source": [
    "src\n",
    "data\n",
    "Soja\n",
    "df_soja.parquet\n",
    "src\n",
    "models\n",
    "output_test\n",
    "src\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45dea1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\n"
     ]
    }
   ],
   "source": [
    "# Load data (uses the same preprocessing as treino)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, scaler, feature_names = prepare_dataset(parquet_path)\n",
    "print(\f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c9b481a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Nenhum modelo encontrado em {model_keras} ou {model_h5}. Rode o treino primeiro.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded model from .h5 checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m     10\u001b[0m         \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNenhum modelo encontrado em \u001b[39m\u001b[38;5;132;01m{model_keras}\u001b[39;00m\u001b[38;5;124m ou \u001b[39m\u001b[38;5;132;01m{model_h5}\u001b[39;00m\u001b[38;5;124m. Rode o treino primeiro.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Nenhum modelo encontrado em {model_keras} ou {model_h5}. Rode o treino primeiro."
     ]
    }
   ],
   "source": [
    "# Load model (prefer .keras native format, fallback to .h5)\n",
    "if os.path.exists(model_keras):\n",
    "    model = load_model(model_keras)\n",
    "    print(\"Loaded model from .keras\")\n",
    "elif os.path.exists(model_h5):\n",
    "    model = load_model(model_h5)\n",
    "    print(\"Loaded model from .h5 checkpoint\")\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \f\"Nenhum modelo encontrado em {model_keras} ou {model_h5}. Rode o treino primeiro.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31201b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stored metrics if present\n",
    "if os.path.exists(metrics_path):\n",
    "    stored_metrics = joblib.load(metrics_path)\n",
    "    print(\"Stored metrics:\")\n",
    "    print(stored_metrics)\n",
    "else:\n",
    "    stored_metrics = None\n",
    "    print(\"No stored metrics found at {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac9725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "preds = model.predict(X_test)\n",
    "# preds is a list of arrays (one per output). Stack into (n_samples, n_outputs)\n",
    "y_pred = np.vstack([p.ravel() for p in preds]).T\n",
    "y_true = y_test\n",
    "print(\f\"Prediction shape: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DataFrame with true and predicted values (first 500 rows for CSV)\n",
    "targets = [\"Toneladas\", \"Quilograma Líquido\", \"Valor US$ FOB\"]\n",
    "df_pred = pd.DataFrame()\n",
    "for i, t in enumerate(targets):\n",
    "    df_pred[f\"y_true_{t}\"] = y_true[:, i]\n",
    "    df_pred[f\"y_pred_{t}\"] = y_pred[:, i]\n",
    "\n",
    "# Save sample CSV (first 500 rows)\n",
    "df_pred.head(500).to_csv(pred_csv, index=False)\n",
    "print(\f\"Saved predictions sample to {pred_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting: scatter y_true vs y_pred and residuals for each target\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 14))\n",
    "for i, t in enumerate(targets):\n",
    "    ax_scatter = axes[i, 0]\n",
    "    ax_hist = axes[i, 1]\n",
    "\n",
    "    y_t = y_true[:, i]\n",
    "    y_p = y_pred[:, i]\n",
    "    res = y_t - y_p\n",
    "\n",
    "    # Scatter\n",
    "    ax_scatter.scatter(y_t, y_p, alpha=0.4, s=10)\n",
    "    lims = [np.nanmin(np.concatenate([y_t, y_p])), np.nanmax(np.concatenate([y_t, y_p]))]\n",
    "    ax_scatter.plot(lims, lims, color=\"red\", linestyle=\"--\")\n",
    "    ax_scatter.set_title(f\"{t}: True vs Pred\")\n",
    "    ax_scatter.set_xlabel(\"True\")\n",
    "    ax_scatter.set_ylabel(\"Pred\")\n",
    "\n",
    "    # Residual histogram + KDE\n",
    "    sns.histplot(res, kde=True, ax=ax_hist, bins=50)\n",
    "    ax_hist.set_title(f\"{t}: Residuals (true - pred)\")\n",
    "\n",
    "    # Print metrics\n",
    "    mse = mean_squared_error(y_t, y_p)\n",
    "    mae = mean_absolute_error(y_t, y_p)\n",
    "    print(f\"{t} - MSE: {mse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(pred_fig, dpi=150)\n",
    "print(\f\"Saved figure to {pred_fig}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4dc846",
   "metadata": {},
   "source": [
    "## Localização dos artefatos gerados\n",
    "\n",
    "- Modelo salvo: `src/models/output_test/soja_model_saved.keras` (ou `soja_model_best.h5`)\n",
    "- Scaler: `src/models/output_test/scaler.joblib`\n",
    "- Métricas: `src/models/output_test/metrics.joblib`\n",
    "- Previsões (amostra): `src/models/output_test/predictions_sample.csv`\n",
    "- Figura com previsões: `src/models/output_test/soja_predictions.png`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
